{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7b853f-1f32-4ce6-acce-42eafe8a7607",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50302050-4001-4785-a5dd-8a71138dbeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import zipfile\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import AlbertTokenizer, AlbertForSequenceClassification\n",
    "from transformers import DebertaTokenizer, DebertaForSequenceClassification\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Unzip the model file\n",
    "with zipfile.ZipFile('albert-base-v2.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('albert-base-v2')\n",
    "\n",
    "# 加载保存的模型和tokenizer\n",
    "model_path = 'albert-base-v2'\n",
    "model = AlbertForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AlbertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# 将模型移动到GPU（如果可用）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "def predict(text):\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text,\n",
    "        None,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_token_type_ids=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "        pred_label = torch.argmax(logits, dim=1).cpu().numpy()[0]\n",
    "        pred_prob = probs[0][pred_label]\n",
    "\n",
    "    return pred_label, pred_prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139c131e-9744-4efd-9eda-c63ac845e38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Enter text here...',\n",
    "    description='Text:',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='50%', height='100px')\n",
    ")\n",
    "\n",
    "output_label = widgets.Label(value=\"\")\n",
    "output_prob = widgets.Label(value=\"\")\n",
    "\n",
    "def on_button_click(b):\n",
    "    text = text_input.value\n",
    "    label, prob = predict(text)\n",
    "    output_label.value = f'Label: {label}'\n",
    "    output_prob.value = f'Probability: {prob:.4f}'\n",
    "\n",
    "button = widgets.Button(\n",
    "    description='Predict',\n",
    "    disabled=False,\n",
    "    button_style='',\n",
    "    tooltip='Click to predict',\n",
    "    icon='check'\n",
    ")\n",
    "\n",
    "button.on_click(on_button_click)\n",
    "\n",
    "\n",
    "display(text_input, button, output_label, output_prob)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
